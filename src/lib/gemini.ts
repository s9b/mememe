/**
 * Google Gemini AI integration for meme caption generation
 * Free alternative to OpenAI with generous free tier
 */

interface GeminiRequest {
  contents: Array<{
    parts: Array<{
      text: string;
    }>;
  }>;
  generationConfig?: {
    temperature?: number;
    topK?: number;
    topP?: number;
    maxOutputTokens?: number;
    stopSequences?: string[];
  };
}

interface GeminiResponse {
  candidates: Array<{
    content: {
      parts: Array<{
        text: string;
      }>;
      role: string;
    };
    finishReason: string;
    index: number;
  }>;
  promptFeedback: {
    safetyRatings: Array<{
      category: string;
      probability: string;
    }>;
  };
}

/**
 * Generate meme captions using Google Gemini API (free alternative to OpenAI)
 * @param topic - The topic for the meme captions
 * @param templateId - Optional template ID to provide context
 * @returns Promise resolving to an array of 3 captions
 */
export async function generateCaptionsWithGemini(topic: string, templateId?: string): Promise<string[]> {
  if (!topic) {
    throw new Error('Topic is required');
  }

  const apiKey = process.env.GOOGLE_GEMINI_API_KEY;
  if (!apiKey) {
    console.warn('Google Gemini API key not found, using fallback captions');
    return [
      `When ${topic} happens`,
      `That feeling when ${topic}`,
      `${topic} be like`
    ];
  }

  const prompt = `You are a meme caption generator. Create exactly 3 short, funny meme captions (max 10 words each) about "${topic}". Each caption should be on its own line. Make them humorous but appropriate. Template context: ${templateId || 'general meme'}

Examples:
- When Monday hits different
- That feeling when it's Friday
- Coffee be like my bestie

Generate 3 captions for topic: ${topic}`;

  try {
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: prompt
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 100,
        }
      } as GeminiRequest)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Gemini API error:', errorText);
      throw new Error(`Gemini API error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json() as GeminiResponse;
    
    if (!data.candidates || data.candidates.length === 0) {
      throw new Error('No captions generated by Gemini');
    }

    const content = data.candidates[0].content.parts[0].text.trim();
    
    // Split by newlines and filter out empty lines
    const captions = content.split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0)
      .map(line => {
        // Remove numbering or bullet points
        return line.replace(/^\d+\.\s*/, '').replace(/^[-â€¢*]\s*/, '').trim();
      });
    
    // Ensure we have exactly 3 captions
    if (captions.length < 3) {
      // Pad with fallback captions if needed
      while (captions.length < 3) {
        const fallbacks = [
          `When ${topic} happens`,
          `That feeling when ${topic}`,
          `${topic} be like`,
          `Me when ${topic}`,
          `${topic} hits different`
        ];
        captions.push(fallbacks[captions.length] || `Caption about ${topic}`);
      }
    }
    
    return captions.slice(0, 3);
  } catch (error) {
    console.error('Error generating captions with Gemini:', error);
    
    // Fallback to template-based captions
    console.warn('Using fallback captions due to Gemini error');
    return [
      `When ${topic} happens`,
      `That feeling when ${topic}`,
      `${topic} be like`
    ];
  }
}

/**
 * Moderate content using Google Gemini (free alternative to OpenAI moderation)
 * @param text - The text to moderate
 * @returns Promise resolving to moderation result
 */
export async function moderateWithGemini(text: string): Promise<{ flagged: boolean; reasons?: string[] }> {
  if (!text || text.trim() === '') {
    return { flagged: false };
  }

  const apiKey = process.env.GOOGLE_GEMINI_API_KEY;
  if (!apiKey) {
    console.warn('Google Gemini API key not found, skipping content moderation');
    return { flagged: false };
  }

  const prompt = `Analyze this text for inappropriate content. Respond with only "SAFE" or "UNSAFE":

Text: "${text}"

Consider it UNSAFE if it contains:
- Hate speech or discrimination
- Explicit violence or graphic content
- Sexual or adult content
- Harassment or bullying
- Illegal activities

Respond with only one word: SAFE or UNSAFE`;

  try {
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: prompt
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.1,
          maxOutputTokens: 10,
        }
      } as GeminiRequest)
    });

    if (!response.ok) {
      console.warn('Gemini moderation API error, allowing content');
      return { flagged: false };
    }

    const data = await response.json() as GeminiResponse;
    
    if (!data.candidates || data.candidates.length === 0) {
      return { flagged: false };
    }

    const result = data.candidates[0].content.parts[0].text.trim().toUpperCase();
    const isUnsafe = result.includes('UNSAFE');
    
    return {
      flagged: isUnsafe,
      reasons: isUnsafe ? ['content_policy_violation'] : undefined
    };
  } catch (error) {
    console.error('Error during Gemini content moderation:', error);
    // Fail safe - allow content if moderation fails
    return { flagged: false };
  }
}